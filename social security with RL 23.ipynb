{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforced learning, työllistyminen ja Suomen sosiaaliturva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tässä tehdään laskelmat artikkelia varten. Käytössä on gym-ympäristö _unemployment-v1_ , johon on toteutettu yksityiskohtaisempi työttömyysturvamalli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Colab, install fin_benefits and unemployment-gym from Github\n",
    "#!pip install -q git+https://github.com/ajtanskanen/benefits.git  \n",
    "#!pip install -q git+https://github.com/ajtanskanen/econogym.git\n",
    "#!pip install -q git+https://github.com/ajtanskanen/lifecycle-rl.git\n",
    "\n",
    "# and then restart kernel\n",
    "  \n",
    "  # For a specific version:\n",
    "#!pip install tensorflow==1.15\n",
    "#!pip install stable-baselines==2.8\n",
    "  \n",
    "# restart kernel after running pip's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then load all modules and set parameters for simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifecycle_rl import Lifecycle\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "# varoitukset piiloon (Stable baseline ei ole vielä Tensorflow 2.0-yhteensopiva, ja Tensorflow 1.15 valittaa paljon)\n",
    "# ei taida toimia piilottaminen\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# parameters for the simulation\n",
    "# episode = 51 / 205 timesteps (1y/3m timestep)\n",
    "pop_size=10_000 # size of the population to be simulated\n",
    "size1=10_000_000 #0_000 # number of timesteps in phase 1 training (callback not used)\n",
    "size2=100_000_000 #0_000 # number of timesteps in phase 2 training (callback is used to save the best results)\n",
    "size3=10_000_000 # number of timesteps in phase 1 training (callback not used) for policy changes\n",
    "batch1=1_00 # size of minibatch in phase 1 as number of episodes\n",
    "batch2=9_00  # size of minibatch in phase 1 as number of episodes\n",
    "callback_minsteps=batch2 # how many episodes callback needs \n",
    "deterministic=True # use deterministic prediction (True) or probabilitic prediction (False)\n",
    "mortality=False # include mortality in computations\n",
    "randomness=True # include externally given, random state-transitions (parental leaves, disability, lay-offs) \n",
    "pinkslip=True # include lay-offs at 5 percent level each year\n",
    "rlmodel='acktr' # use ACKTR algorithm\n",
    "twostage=False # ajataan kahdessa vaiheessa vai ei\n",
    "perusmalli='best/malli_perus3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Nykymalli \n",
    "\n",
    "Lasketaan työllisyysasteet nykymallissa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mortality included\n",
      "Parameters of lifecycle:\n",
      "timestep 0.25\n",
      "gamma 0.9793703613355593 (0.9200000000000003 per anno)\n",
      "min_age 20\n",
      "max_age 70\n",
      "min_retirementage 63.5\n",
      "max_retirementage 68.5\n",
      "ansiopvraha_kesto300 None\n",
      "ansiopvraha_kesto400 None\n",
      "ansiopvraha_toe None\n",
      "perustulo False\n",
      "karenssi_kesto 0.25\n",
      "mortality False\n",
      "randomness True\n",
      "include_putki None\n",
      "include_pinkslip True\n",
      "step 0.25\n",
      "\n",
      "train...\n",
      "phase 1\n",
      "batch 9 learning rate 0.125 scaled 0.375\n",
      "training...\n",
      "---------------------------------\n",
      "| explained_variance | 0.974    |\n",
      "| fps                | 2322     |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.764    |\n",
      "| policy_loss        | -0.0675  |\n",
      "| total_timesteps    | 0        |\n",
      "| value_loss         | 0.344    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.615    |\n",
      "| fps                | 2598     |\n",
      "| nupdates           | 10       |\n",
      "| policy_entropy     | 0.734    |\n",
      "| policy_loss        | -0.988   |\n",
      "| total_timesteps    | 196353   |\n",
      "| value_loss         | 7.09     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.581    |\n",
      "| fps                | 2585     |\n",
      "| nupdates           | 20       |\n",
      "| policy_entropy     | 0.818    |\n",
      "| policy_loss        | 14.3     |\n",
      "| total_timesteps    | 414523   |\n",
      "| value_loss         | 309      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.684    |\n",
      "| fps                | 2580     |\n",
      "| nupdates           | 30       |\n",
      "| policy_entropy     | 0.792    |\n",
      "| policy_loss        | 10.2     |\n",
      "| total_timesteps    | 632693   |\n",
      "| value_loss         | 170      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.531    |\n",
      "| fps                | 2583     |\n",
      "| nupdates           | 40       |\n",
      "| policy_entropy     | 0.765    |\n",
      "| policy_loss        | 4.12     |\n",
      "| total_timesteps    | 850863   |\n",
      "| value_loss         | 35.9     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.691    |\n",
      "| fps                | 2583     |\n",
      "| nupdates           | 50       |\n",
      "| policy_entropy     | 0.708    |\n",
      "| policy_loss        | -1.24    |\n",
      "| total_timesteps    | 1069033  |\n",
      "| value_loss         | 7.08     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.817    |\n",
      "| fps                | 2584     |\n",
      "| nupdates           | 60       |\n",
      "| policy_entropy     | 0.663    |\n",
      "| policy_loss        | -2.17    |\n",
      "| total_timesteps    | 1287203  |\n",
      "| value_loss         | 14.5     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.834    |\n",
      "| fps                | 2586     |\n",
      "| nupdates           | 70       |\n",
      "| policy_entropy     | 0.678    |\n",
      "| policy_loss        | 0.222    |\n",
      "| total_timesteps    | 1505373  |\n",
      "| value_loss         | 2.13     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.914    |\n",
      "| fps                | 2585     |\n",
      "| nupdates           | 80       |\n",
      "| policy_entropy     | 0.733    |\n",
      "| policy_loss        | 1.19     |\n",
      "| total_timesteps    | 1723543  |\n",
      "| value_loss         | 3.96     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.914    |\n",
      "| fps                | 2584     |\n",
      "| nupdates           | 90       |\n",
      "| policy_entropy     | 0.748    |\n",
      "| policy_loss        | -0.902   |\n",
      "| total_timesteps    | 1941713  |\n",
      "| value_loss         | 2.45     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.908    |\n",
      "| fps                | 2584     |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 0.748    |\n",
      "| policy_loss        | -0.517   |\n",
      "| total_timesteps    | 2159883  |\n",
      "| value_loss         | 1.6      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.951    |\n",
      "| fps                | 2582     |\n",
      "| nupdates           | 110      |\n",
      "| policy_entropy     | 0.749    |\n",
      "| policy_loss        | 0.741    |\n",
      "| total_timesteps    | 2378053  |\n",
      "| value_loss         | 1.66     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.947    |\n",
      "| fps                | 2582     |\n",
      "| nupdates           | 120      |\n",
      "| policy_entropy     | 0.738    |\n",
      "| policy_loss        | -0.571   |\n",
      "| total_timesteps    | 2596223  |\n",
      "| value_loss         | 1.09     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.944    |\n",
      "| fps                | 2581     |\n",
      "| nupdates           | 130      |\n",
      "| policy_entropy     | 0.761    |\n",
      "| policy_loss        | 0.0836   |\n",
      "| total_timesteps    | 2814393  |\n",
      "| value_loss         | 0.686    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.959    |\n",
      "| fps                | 2579     |\n",
      "| nupdates           | 140      |\n",
      "| policy_entropy     | 0.752    |\n",
      "| policy_loss        | 0.322    |\n",
      "| total_timesteps    | 3032563  |\n",
      "| value_loss         | 0.802    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.956    |\n",
      "| fps                | 2578     |\n",
      "| nupdates           | 150      |\n",
      "| policy_entropy     | 0.753    |\n",
      "| policy_loss        | -0.491   |\n",
      "| total_timesteps    | 3250733  |\n",
      "| value_loss         | 1        |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.959    |\n",
      "| fps                | 2578     |\n",
      "| nupdates           | 160      |\n",
      "| policy_entropy     | 0.753    |\n",
      "| policy_loss        | 0.483    |\n",
      "| total_timesteps    | 3468903  |\n",
      "| value_loss         | 0.92     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.966    |\n",
      "| fps                | 2578     |\n",
      "| nupdates           | 170      |\n",
      "| policy_entropy     | 0.77     |\n",
      "| policy_loss        | -0.334   |\n",
      "| total_timesteps    | 3687073  |\n",
      "| value_loss         | 0.646    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.964    |\n",
      "| fps                | 2579     |\n",
      "| nupdates           | 180      |\n",
      "| policy_entropy     | 0.764    |\n",
      "| policy_loss        | 0.09     |\n",
      "| total_timesteps    | 3905243  |\n",
      "| value_loss         | 0.502    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.961    |\n",
      "| fps                | 2579     |\n",
      "| nupdates           | 190      |\n",
      "| policy_entropy     | 0.809    |\n",
      "| policy_loss        | 0.00402  |\n",
      "| total_timesteps    | 4123413  |\n",
      "| value_loss         | 0.514    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.963    |\n",
      "| fps                | 2578     |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 0.82     |\n",
      "| policy_loss        | 0.0921   |\n",
      "| total_timesteps    | 4341583  |\n",
      "| value_loss         | 0.476    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.969    |\n",
      "| fps                | 2577     |\n",
      "| nupdates           | 210      |\n",
      "| policy_entropy     | 0.815    |\n",
      "| policy_loss        | -0.127   |\n",
      "| total_timesteps    | 4559753  |\n",
      "| value_loss         | 0.393    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.967    |\n",
      "| fps                | 2577     |\n",
      "| nupdates           | 220      |\n",
      "| policy_entropy     | 0.816    |\n",
      "| policy_loss        | 0.106    |\n",
      "| total_timesteps    | 4777923  |\n",
      "| value_loss         | 0.447    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.963    |\n",
      "| fps                | 2576     |\n",
      "| nupdates           | 230      |\n",
      "| policy_entropy     | 0.798    |\n",
      "| policy_loss        | -0.159   |\n",
      "| total_timesteps    | 4996093  |\n",
      "| value_loss         | 0.489    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.969    |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 240      |\n",
      "| policy_entropy     | 0.804    |\n",
      "| policy_loss        | 0.00164  |\n",
      "| total_timesteps    | 5214263  |\n",
      "| value_loss         | 0.366    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.974    |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 250      |\n",
      "| policy_entropy     | 0.789    |\n",
      "| policy_loss        | 0.0332   |\n",
      "| total_timesteps    | 5432433  |\n",
      "| value_loss         | 0.349    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| explained_variance | 0.975    |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 260      |\n",
      "| policy_entropy     | 0.81     |\n",
      "| policy_loss        | 0.0085   |\n",
      "| total_timesteps    | 5650603  |\n",
      "| value_loss         | 0.348    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.965    |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 270      |\n",
      "| policy_entropy     | 0.801    |\n",
      "| policy_loss        | 0.00686  |\n",
      "| total_timesteps    | 5868773  |\n",
      "| value_loss         | 0.463    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.958    |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 280      |\n",
      "| policy_entropy     | 0.802    |\n",
      "| policy_loss        | -0.0394  |\n",
      "| total_timesteps    | 6086943  |\n",
      "| value_loss         | 0.494    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.972    |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 290      |\n",
      "| policy_entropy     | 0.801    |\n",
      "| policy_loss        | -0.0162  |\n",
      "| total_timesteps    | 6305113  |\n",
      "| value_loss         | 0.392    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.977    |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 0.797    |\n",
      "| policy_loss        | 0.0942   |\n",
      "| total_timesteps    | 6523283  |\n",
      "| value_loss         | 0.343    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.97     |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 310      |\n",
      "| policy_entropy     | 0.788    |\n",
      "| policy_loss        | 0.0121   |\n",
      "| total_timesteps    | 6741453  |\n",
      "| value_loss         | 0.344    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.955    |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 320      |\n",
      "| policy_entropy     | 0.794    |\n",
      "| policy_loss        | -0.0439  |\n",
      "| total_timesteps    | 6959623  |\n",
      "| value_loss         | 0.559    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.97     |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 330      |\n",
      "| policy_entropy     | 0.779    |\n",
      "| policy_loss        | -0.00194 |\n",
      "| total_timesteps    | 7177793  |\n",
      "| value_loss         | 0.425    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.962    |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 340      |\n",
      "| policy_entropy     | 0.783    |\n",
      "| policy_loss        | 0.0617   |\n",
      "| total_timesteps    | 7395963  |\n",
      "| value_loss         | 0.481    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.971    |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 350      |\n",
      "| policy_entropy     | 0.776    |\n",
      "| policy_loss        | -0.00681 |\n",
      "| total_timesteps    | 7614133  |\n",
      "| value_loss         | 0.396    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.964    |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 360      |\n",
      "| policy_entropy     | 0.779    |\n",
      "| policy_loss        | -0.0326  |\n",
      "| total_timesteps    | 7832303  |\n",
      "| value_loss         | 0.467    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.965    |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 370      |\n",
      "| policy_entropy     | 0.779    |\n",
      "| policy_loss        | -0.00858 |\n",
      "| total_timesteps    | 8050473  |\n",
      "| value_loss         | 0.461    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.968    |\n",
      "| fps                | 2575     |\n",
      "| nupdates           | 380      |\n",
      "| policy_entropy     | 0.777    |\n",
      "| policy_loss        | -0.0213  |\n",
      "| total_timesteps    | 8268643  |\n",
      "| value_loss         | 0.462    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.952    |\n",
      "| fps                | 2576     |\n",
      "| nupdates           | 390      |\n",
      "| policy_entropy     | 0.777    |\n",
      "| policy_loss        | -0.0496  |\n",
      "| total_timesteps    | 8486813  |\n",
      "| value_loss         | 0.477    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.966    |\n",
      "| fps                | 2576     |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 0.768    |\n",
      "| policy_loss        | -0.00285 |\n",
      "| total_timesteps    | 8704983  |\n",
      "| value_loss         | 0.405    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.964    |\n",
      "| fps                | 2577     |\n",
      "| nupdates           | 410      |\n",
      "| policy_entropy     | 0.771    |\n",
      "| policy_loss        | -0.00982 |\n",
      "| total_timesteps    | 8923153  |\n",
      "| value_loss         | 0.51     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.974    |\n",
      "| fps                | 2577     |\n",
      "| nupdates           | 420      |\n",
      "| policy_entropy     | 0.78     |\n",
      "| policy_loss        | 0.00481  |\n",
      "| total_timesteps    | 9141323  |\n",
      "| value_loss         | 0.332    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.964    |\n",
      "| fps                | 2576     |\n",
      "| nupdates           | 430      |\n",
      "| policy_entropy     | 0.787    |\n",
      "| policy_loss        | -0.0194  |\n",
      "| total_timesteps    | 9359493  |\n",
      "| value_loss         | 0.405    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.975    |\n",
      "| fps                | 2576     |\n",
      "| nupdates           | 440      |\n",
      "| policy_entropy     | 0.769    |\n",
      "| policy_loss        | -0.00665 |\n",
      "| total_timesteps    | 9577663  |\n",
      "| value_loss         | 0.327    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.971    |\n",
      "| fps                | 2576     |\n",
      "| nupdates           | 450      |\n",
      "| policy_entropy     | 0.757    |\n",
      "| policy_loss        | 0.0139   |\n",
      "| total_timesteps    | 9795833  |\n",
      "| value_loss         | 0.4      |\n",
      "---------------------------------\n",
      "done\n",
      "acktr\n",
      "simulating  best/malli_perus3\n"
     ]
    }
   ],
   "source": [
    "cc1=Lifecycle(env='unemployment-v1',minimal=False,mortality=mortality,perustulo=False,\n",
    "              randomness=randomness,pinkslip=pinkslip,plotdebug=False)\n",
    "cc1.explain()\n",
    "cc1.run_results(debug=False,steps1=size1,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                train=True,predict=True,batch1=batch1,batch2=batch2,\n",
    "                save=perusmalli,plot=True,cont=True,start_from=perusmalli,results='results/perus_results3',\n",
    "                callback_minsteps=callback_minsteps,rlmodel=rlmodel,twostage=twostage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cc1=Lifecycle(env='unemployment-v1',minimal=False,mortality=mortality,perustulo=False,\n",
    "#              randomness=randomness,pinkslip=pinkslip,plotdebug=False)\n",
    "#\n",
    "#cc1.render(load='results/perus_results3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-network\n",
    "\n",
    "Kokeillaan toista menetelmää ratkaisuun. Muutos on helppo tehdä, muutetaan vain algoritmin valintaa säätelevän parametrin _rlmodel_ arvo, ja varmistetaan että kaikki lähtee alusta liikkeelle (_cont=False_). Deep Q-network on menetelmänä hitaampi kuin ACKTR, joten tässä aika-askelten määrä on rajattu 1 000 000:aan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mortality included\n",
      "Parameters of lifecycle:\n",
      "timestep 0.25\n",
      "gamma 0.9793703613355593 (0.9200000000000003 per anno)\n",
      "min_age 20\n",
      "max_age 70\n",
      "min_retirementage 63.5\n",
      "max_retirementage 68.5\n",
      "ansiopvraha_kesto300 None\n",
      "ansiopvraha_kesto400 None\n",
      "ansiopvraha_toe None\n",
      "perustulo False\n",
      "karenssi_kesto 0.25\n",
      "mortality False\n",
      "randomness True\n",
      "include_putki None\n",
      "include_pinkslip True\n",
      "step 0.25\n",
      "\n",
      "train...\n",
      "phase 1\n",
      "batch 1 learning rate 0.25 scaled 0.25\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:57: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py:122: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:147: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:149: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:372: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:107: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:108: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "training...\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/base_class.py:1035: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:187: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/a2c/utils.py:581: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py:250: The name tf.RunOptions is deprecated. Please use tf.compat.v1.RunOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py:251: The name tf.RunMetadata is deprecated. Please use tf.compat.v1.RunMetadata instead.\n",
      "\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 230      |\n",
      "| steps                   | 200798   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 60       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 235      |\n",
      "| steps                   | 401798   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 235      |\n",
      "| steps                   | 602798   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 21       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 236      |\n",
      "| steps                   | 803798   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 236      |\n",
      "| steps                   | 1004798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 236      |\n",
      "| steps                   | 1205798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 238      |\n",
      "| steps                   | 1406798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 235      |\n",
      "| steps                   | 1607798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 239      |\n",
      "| steps                   | 1808798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 239      |\n",
      "| steps                   | 2009798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 240      |\n",
      "| steps                   | 2210798  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 237      |\n",
      "| steps                   | 2411798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 239      |\n",
      "| steps                   | 2612798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 238      |\n",
      "| steps                   | 2813798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 239      |\n",
      "| steps                   | 3014798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 238      |\n",
      "| steps                   | 3215798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 238      |\n",
      "| steps                   | 3416798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 237      |\n",
      "| steps                   | 3617798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 238      |\n",
      "| steps                   | 3818798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 236      |\n",
      "| steps                   | 4019798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 239      |\n",
      "| steps                   | 4220798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 236      |\n",
      "| steps                   | 4421798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 237      |\n",
      "| steps                   | 4622798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 237      |\n",
      "| steps                   | 4823798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 236      |\n",
      "| steps                   | 5024798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 239      |\n",
      "| steps                   | 5225798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 237      |\n",
      "| steps                   | 5426798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 236      |\n",
      "| steps                   | 5627798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 238      |\n",
      "| steps                   | 5828798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 240      |\n",
      "| steps                   | 6029798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 234      |\n",
      "| steps                   | 6230798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 234      |\n",
      "| steps                   | 6431798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 237      |\n",
      "| steps                   | 6632798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 233      |\n",
      "| steps                   | 6833798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 236      |\n",
      "| steps                   | 7034798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 237      |\n",
      "| steps                   | 7235798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 238      |\n",
      "| steps                   | 7436798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 235      |\n",
      "| steps                   | 7637798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 235      |\n",
      "| steps                   | 7838798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 233      |\n",
      "| steps                   | 8039798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 237      |\n",
      "| steps                   | 8240798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 236      |\n",
      "| steps                   | 8441798  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 236      |\n",
      "| steps                   | 8642798  |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cc1q=Lifecycle(env='unemployment-v1',minimal=False,mortality=mortality,perustulo=False,\n",
    "              randomness=randomness,pinkslip=pinkslip,plotdebug=False)\n",
    "cc1q.explain()\n",
    "cc1q.run_results(debug=False,steps1=1_000_000,steps2=size2,pop=1_000,deterministic=deterministic,\n",
    "                train=True,predict=True,batch1=1,batch2=batch2,\n",
    "                save=perusmalli+'_dqn',plot=True,cont=False,start_from=perusmalli+'_dqn',results='results/perus_results3_dqn',\n",
    "                callback_minsteps=callback_minsteps,rlmodel='dqn',twostage=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Työttömyysputken poisto\n",
    "\n",
    "Työttömyysputkelle meneminen on usein hyvin suosittua elinkaarimalleissa. Tarkastellaan millainen työllisyysvaikutus on putken poistamisella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cc1_putki=Lifecycle(env='unemployment-v1',minimal=False,include_putki=False,mortality=mortality,\n",
    "                    perustulo=False,randomness=randomness)\n",
    "cc1_putki.run_results(debug=False,steps1=size1,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                      train=True,predict=True,batch1=batch1,batch2=batch2,save='best/malli_putki',\n",
    "                      plot=True,results='results/putki_results',start_from=perusmalli,cont=True,\n",
    "                      callback_minsteps=callback_minsteps,twostage=twostage)\n",
    "cc1_putki.render(load='results/putki_results')\n",
    "cc1_putki.compare_with(cc1)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc1_putki.render(load='results/putki_results')\n",
    "cc1_putki.compare_with(cc1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porrastettu työttömyysturva\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc2_porras=Lifecycle(env='unemploymentSteps-v1',minimal=False,mortality=mortality,perustulo=False,\n",
    "              randomness=randomness)\n",
    "cc2_porras.run_results(debug=False,steps1=size3,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                train=True,predict=True,batch1=batch1,batch2=batch2,save='best/malli_steps',plot=True,\n",
    "                results='results/steps_results',start_from=perusmalli,cont=True,\n",
    "                callback_minsteps=callback_minsteps,twostage=twostage)\n",
    "cc2_porras.render(load='results/steps_results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2_porras.compare_with(cc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EK:n malli\n",
    "\n",
    "Lasketaan vertailukelpoiset työllisyysasteet EK:n ehdottamalla mallilla. Mallissa on toteuttu muutoksia ansiosidonnaiseen työttömyysturvaan, asumistukeen, toimeentulotukeen ja verotukseen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc2=Lifecycle(env='unemploymentEK-v1',minimal=False,mortality=mortality,perustulo=False,\n",
    "              randomness=randomness)\n",
    "cc2.run_results(debug=False,steps1=size3,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                train=True,predict=True,batch1=batch1,batch2=batch2,save='best/malli_ek',plot=True,\n",
    "                results='results/ek_results',start_from=perusmalli,cont=True,\n",
    "                callback_minsteps=callback_minsteps,twostage=twostage)\n",
    "#cc2.render(load='results/ek_results')\n",
    "#cc2.load_sim(load='results/ek_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc2.compare_with(cc1)\n",
    "#print(cc1.episodestats.empstate/cc1.n_pop,cc2.episodestats.empstate/cc2.n_pop)\n",
    "#cc2.episodestats.load_sim('results/ek_res__best')\n",
    "#cc2.episodestats.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Verifiointi\n",
    "\n",
    "Ajetaan sama simulaatio kaksi kertaa ja tarkastetaan että tulokset ovat sama. Tässä ideana on varmistaa, että satunnaisuus ei sotke tulosten arviointia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Työssäoloehdon pituus 12 kk\n",
    "\n",
    "Entä jos työssäoloehto olisikin 12 kuukautta pitkä nykyisen 6 kuukauden sijaan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc1_toe=Lifecycle(env='unemployment-v1',minimal=False,ansiopvraha_toe=1.0,mortality=mortality,\n",
    "                  perustulo=False,randomness=randomness)\n",
    "cc1_toe.run_results(debug=False,steps1=size3,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                    train=True,predict=True,batch1=batch1,batch2=batch2,save='best/best_12kk',plot=True,\n",
    "                    results='results/12kk_results',start_from=perusmalli,cont=True,\n",
    "                callback_minsteps=callback_minsteps,twostage=twostage)\n",
    "cc1_toe.render(load='results/12kk_results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1_toe.compare_with(cc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ansiosidonnaisen päivärahan lyhennys 50 pv\n",
    "\n",
    "Tarkastellaan, miten työllisyyteen vaikuttaisi ansiosidonnaisen päivärahan lyhentäminen 50 päivällä. Tällöin alle kolmen vuoden työhistorialla ansiosidonnaisen päivärahan enimmäiskesto olisi 250 pv ja pidemmällä työhistorialla enimmäiskesto olisi 350 pv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc1_350=Lifecycle(env='unemployment-v1',minimal=False,ansiopvraha_kesto300=250,ansiopvraha_kesto400=350,\n",
    "                  mortality=mortality,perustulo=False,randomness=randomness)\n",
    "cc1_350.run_results(debug=False,steps1=size3,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                    train=True,predict=True,batch1=batch1,batch2=batch2,save='best/malli_50pv',plot=True,\n",
    "                    results='results/50pv_results',start_from=perusmalli,cont=True,\n",
    "                    callback_minsteps=callback_minsteps,twostage=twostage)\n",
    "cc1_350.render(load='results/50pv_results')\n",
    "cc1_350.compare_with(cc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perustulo\n",
    "\n",
    "Alustava versio. Tulee muuttumaan, kun mukana koko mallli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc1_pt=Lifecycle(env='unemployment-v1',minimal=False,perustulo=True,mortality=mortality,\n",
    "                 randomness=randomness)\n",
    "cc1_pt.run_results(debug=False,steps1=size3,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                   train=True,predict=True,batch1=batch1,batch2=batch2,save='best/malli_pt',plot=True,\n",
    "                   results='results/perustulo_results',start_from=perusmalli,cont=True,\n",
    "                callback_minsteps=callback_minsteps,twostage=twostage)\n",
    "cc1_pt.render(load='results/perustulo_results')\n",
    "cc1_pt.compare_with(cc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 300 vs 400 päivän kesto ansiosidonnaisessa\n",
    "\n",
    "Mikä on alle kolmen vuoden työhistorian lyhyemmän (300 pv) ansiosidonnaisen päivärahan enimmäiskeston vaikutus työllisyyteen? Kokeillaan miten työllisyyteen vaikuttaisi sen pidentäminen 400 päivään."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cc1_400=Lifecycle(env='unemployment-v1',minimal=False,ansiopvraha_kesto300=400,mortality=mortality,\n",
    "                  perustulo=False,randomness=randomness)\n",
    "cc1_400.run_results(debug=False,steps1=size3,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                    train=True,predict=True,batch1=batch1,batch2=batch2,save='best/malli_300pv',plot=True,\n",
    "                    results='results/300pv_results',start_from=perusmalli,cont=True,\n",
    "                callback_minsteps=callback_minsteps,twostage=twostage)\n",
    "cc1_400.render(load='results/300pv_results')\n",
    "cc1_400.compare_with(cc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
