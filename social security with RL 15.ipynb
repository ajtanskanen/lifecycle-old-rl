{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforced learning, työllistyminen ja Suomen sosiaaliturva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tässä tehdään laskelmat artikkelia varten. Käytössä on gym-ympäristö _unemployment-v1_ , johon on toteutettu yksityiskohtaisempi työttömyysturvamalli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Colab, install fin_benefits and unemployment-gym from Github\n",
    "#!pip install -q git+https://github.com/ajtanskanen/benefits.git  \n",
    "#!pip install -q git+https://github.com/ajtanskanen/econogym.git\n",
    "#!pip install -q git+https://github.com/ajtanskanen/lifecycle-rl.git\n",
    "\n",
    "# and then restart kernel\n",
    "  \n",
    "  # For a specific version:\n",
    "#!pip install tensorflow==1.15\n",
    "#!pip install stable-baselines==2.8\n",
    "  \n",
    "# restart kernel after running pip's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then load all modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifecycle_rl import Lifecycle\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "# varoitukset piiloon (Stable baseline ei ole vielä Tensorflow 2.0-yhteensopiva, ja Tensorflow 1.5 valittaa paljon)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pop_size=100\n",
    "size1=1\n",
    "size2=200_000\n",
    "batch1=1\n",
    "batch2=1_0\n",
    "deterministic=False # use deterministic prediction (True) or probabilitic prediction (False)\n",
    "mortality=False # include mortality in computations\n",
    "randomness=True # include randomness in the state transitions (e.g., maternity leave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Nykymalli \n",
    "\n",
    "Lasketaan työllisyysasteet nykymallissa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mortality included\n",
      "Parameters of lifecycle:\n",
      "timestep 0.25\n",
      "gamma 0.9793703613355593 (0.9200000000000003 per anno)\n",
      "min_age 20\n",
      "max_age 70\n",
      "min_retirementage 65\n",
      "max_retirementage 70\n",
      "ansiopvraha_kesto300 None\n",
      "ansiopvraha_kesto400 None\n",
      "ansiopvraha_toe None\n",
      "perustulo False\n",
      "karenssi_kesto 0.25\n",
      "mortality False\n",
      "randomness True\n",
      "deterministic False\n",
      "\n",
      "include_putki None\n",
      "step 0.25\n",
      "\n",
      "train...\n",
      "phase 1\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:57: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/policies.py:562: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/a2c/utils.py:156: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/distributions.py:323: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/distributions.py:324: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:312: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:312: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:158: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:97: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:293: The name tf.diag is deprecated. Please use tf.linalg.tensor_diag instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:541: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:543: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:203: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:205: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "training...\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:287: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:288: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:968: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:909: The name tf.mod is deprecated. Please use tf.math.mod instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/kfac.py:616: The name tf.self_adjoint_eig is deprecated. Please use tf.linalg.eigh instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/acktr/acktr.py:300: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "done\n",
      "phase 2\n",
      "init vecmonitor:  tmp/monitor.csv\n",
      "training...\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 213.89427 |\n",
      "| explained_variance | 0.00349   |\n",
      "| fps                | 1735      |\n",
      "| nupdates           | 1         |\n",
      "| policy_entropy     | 1.39      |\n",
      "| policy_loss        | 55.9      |\n",
      "| total_timesteps    | 0         |\n",
      "| value_loss         | 1.73e+03  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | 215.2096 |\n",
      "| explained_variance | 0.00497  |\n",
      "| fps                | 2262     |\n",
      "| nupdates           | 2        |\n",
      "| policy_entropy     | 1.39     |\n",
      "| policy_loss        | 55.2     |\n",
      "| total_timesteps    | 2461     |\n",
      "| value_loss         | 1.68e+03 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 211.79762 |\n",
      "| explained_variance | 0.0125    |\n",
      "| fps                | 2506      |\n",
      "| nupdates           | 3         |\n",
      "| policy_entropy     | 1.39      |\n",
      "| policy_loss        | 49.5      |\n",
      "| total_timesteps    | 4922      |\n",
      "| value_loss         | 1.4e+03   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 210.73332 |\n",
      "| explained_variance | 0.0167    |\n",
      "| fps                | 2652      |\n",
      "| nupdates           | 4         |\n",
      "| policy_entropy     | 1.39      |\n",
      "| policy_loss        | 47.4      |\n",
      "| total_timesteps    | 7383      |\n",
      "| value_loss         | 1.29e+03  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 211.26857 |\n",
      "| explained_variance | 0.0309    |\n",
      "| fps                | 2750      |\n",
      "| nupdates           | 5         |\n",
      "| policy_entropy     | 1.38      |\n",
      "| policy_loss        | 45.7      |\n",
      "| total_timesteps    | 9844      |\n",
      "| value_loss         | 1.21e+03  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 209.60094 |\n",
      "| explained_variance | 0.0751    |\n",
      "| fps                | 2815      |\n",
      "| nupdates           | 6         |\n",
      "| policy_entropy     | 1.38      |\n",
      "| policy_loss        | 36.7      |\n",
      "| total_timesteps    | 12305     |\n",
      "| value_loss         | 820       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 209.94495 |\n",
      "| explained_variance | 0.142     |\n",
      "| fps                | 2859      |\n",
      "| nupdates           | 7         |\n",
      "| policy_entropy     | 1.38      |\n",
      "| policy_loss        | 31.8      |\n",
      "| total_timesteps    | 14766     |\n",
      "| value_loss         | 604       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.99304 |\n",
      "| explained_variance | 0.107     |\n",
      "| fps                | 2907      |\n",
      "| nupdates           | 8         |\n",
      "| policy_entropy     | 1.37      |\n",
      "| policy_loss        | 18.1      |\n",
      "| total_timesteps    | 17227     |\n",
      "| value_loss         | 269       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 209.03975 |\n",
      "| explained_variance | 0.301     |\n",
      "| fps                | 2941      |\n",
      "| nupdates           | 9         |\n",
      "| policy_entropy     | 1.35      |\n",
      "| policy_loss        | 5.18      |\n",
      "| total_timesteps    | 19688     |\n",
      "| value_loss         | 66.1      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 206.83113 |\n",
      "| explained_variance | 0.186     |\n",
      "| fps                | 2846      |\n",
      "| nupdates           | 10        |\n",
      "| policy_entropy     | 1.32      |\n",
      "| policy_loss        | -18.5     |\n",
      "| total_timesteps    | 22149     |\n",
      "| value_loss         | 308       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.89764 |\n",
      "| explained_variance | -0.32     |\n",
      "| fps                | 2772      |\n",
      "| nupdates           | 11        |\n",
      "| policy_entropy     | 1.29      |\n",
      "| policy_loss        | -34.1     |\n",
      "| total_timesteps    | 24610     |\n",
      "| value_loss         | 862       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.39801 |\n",
      "| explained_variance | -0.019    |\n",
      "| fps                | 2712      |\n",
      "| nupdates           | 12        |\n",
      "| policy_entropy     | 1.26      |\n",
      "| policy_loss        | -47.8     |\n",
      "| total_timesteps    | 27071     |\n",
      "| value_loss         | 1.83e+03  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.81848 |\n",
      "| explained_variance | 0.0469    |\n",
      "| fps                | 2664      |\n",
      "| nupdates           | 13        |\n",
      "| policy_entropy     | 1.26      |\n",
      "| policy_loss        | -43.9     |\n",
      "| total_timesteps    | 29532     |\n",
      "| value_loss         | 1.45e+03  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | 208.2318 |\n",
      "| explained_variance | -0.0673  |\n",
      "| fps                | 2624     |\n",
      "| nupdates           | 14       |\n",
      "| policy_entropy     | 1.26     |\n",
      "| policy_loss        | -48.8    |\n",
      "| total_timesteps    | 31993    |\n",
      "| value_loss         | 1.85e+03 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.31328 |\n",
      "| explained_variance | 0.148     |\n",
      "| fps                | 2583      |\n",
      "| nupdates           | 15        |\n",
      "| policy_entropy     | 1.26      |\n",
      "| policy_loss        | -48.2     |\n",
      "| total_timesteps    | 34454     |\n",
      "| value_loss         | 1.77e+03  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.74937 |\n",
      "| explained_variance | 0.173     |\n",
      "| fps                | 2554      |\n",
      "| nupdates           | 16        |\n",
      "| policy_entropy     | 1.26      |\n",
      "| policy_loss        | -47.9     |\n",
      "| total_timesteps    | 36915     |\n",
      "| value_loss         | 1.68e+03  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.30048 |\n",
      "| explained_variance | 0.191     |\n",
      "| fps                | 2527      |\n",
      "| nupdates           | 17        |\n",
      "| policy_entropy     | 1.26      |\n",
      "| policy_loss        | -45.5     |\n",
      "| total_timesteps    | 39376     |\n",
      "| value_loss         | 1.56e+03  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.43925 |\n",
      "| explained_variance | 0.271     |\n",
      "| fps                | 2505      |\n",
      "| nupdates           | 18        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -44.6     |\n",
      "| total_timesteps    | 41837     |\n",
      "| value_loss         | 1.45e+03  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | 207.3153 |\n",
      "| explained_variance | 0.16     |\n",
      "| fps                | 2487     |\n",
      "| nupdates           | 19       |\n",
      "| policy_entropy     | 1.27     |\n",
      "| policy_loss        | -43.3    |\n",
      "| total_timesteps    | 44298    |\n",
      "| value_loss         | 1.35e+03 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 206.65736 |\n",
      "| explained_variance | 0.419     |\n",
      "| fps                | 2470      |\n",
      "| nupdates           | 20        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -42.5     |\n",
      "| total_timesteps    | 46759     |\n",
      "| value_loss         | 1.3e+03   |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | 205.5535 |\n",
      "| explained_variance | 0.198    |\n",
      "| fps                | 2454     |\n",
      "| nupdates           | 21       |\n",
      "| policy_entropy     | 1.26     |\n",
      "| policy_loss        | -43.9    |\n",
      "| total_timesteps    | 49220    |\n",
      "| value_loss         | 1.44e+03 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 205.46657 |\n",
      "| explained_variance | -0.0548   |\n",
      "| fps                | 2441      |\n",
      "| nupdates           | 22        |\n",
      "| policy_entropy     | 1.26      |\n",
      "| policy_loss        | -46.4     |\n",
      "| total_timesteps    | 51681     |\n",
      "| value_loss         | 1.6e+03   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.08546 |\n",
      "| explained_variance | 0.227     |\n",
      "| fps                | 2429      |\n",
      "| nupdates           | 23        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -41       |\n",
      "| total_timesteps    | 54142     |\n",
      "| value_loss         | 1.24e+03  |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | 205.9922 |\n",
      "| explained_variance | 0.156    |\n",
      "| fps                | 2418     |\n",
      "| nupdates           | 24       |\n",
      "| policy_entropy     | 1.27     |\n",
      "| policy_loss        | -44.2    |\n",
      "| total_timesteps    | 56603    |\n",
      "| value_loss         | 1.53e+03 |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 205.11894 |\n",
      "| explained_variance | 0.252     |\n",
      "| fps                | 2409      |\n",
      "| nupdates           | 25        |\n",
      "| policy_entropy     | 1.26      |\n",
      "| policy_loss        | -42.7     |\n",
      "| total_timesteps    | 59064     |\n",
      "| value_loss         | 1.42e+03  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 206.50124 |\n",
      "| explained_variance | 0.325     |\n",
      "| fps                | 2397      |\n",
      "| nupdates           | 26        |\n",
      "| policy_entropy     | 1.26      |\n",
      "| policy_loss        | -40.1     |\n",
      "| total_timesteps    | 61525     |\n",
      "| value_loss         | 1.18e+03  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 204.18755 |\n",
      "| explained_variance | 0.336     |\n",
      "| fps                | 2389      |\n",
      "| nupdates           | 27        |\n",
      "| policy_entropy     | 1.26      |\n",
      "| policy_loss        | -44       |\n",
      "| total_timesteps    | 63986     |\n",
      "| value_loss         | 1.42e+03  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.50085 |\n",
      "| explained_variance | 0.219     |\n",
      "| fps                | 2381      |\n",
      "| nupdates           | 28        |\n",
      "| policy_entropy     | 1.26      |\n",
      "| policy_loss        | -40.1     |\n",
      "| total_timesteps    | 66447     |\n",
      "| value_loss         | 1.15e+03  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 205.83846 |\n",
      "| explained_variance | 0.175     |\n",
      "| fps                | 2374      |\n",
      "| nupdates           | 29        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -39.4     |\n",
      "| total_timesteps    | 68908     |\n",
      "| value_loss         | 1.21e+03  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 206.98215 |\n",
      "| explained_variance | 0.297     |\n",
      "| fps                | 2368      |\n",
      "| nupdates           | 30        |\n",
      "| policy_entropy     | 1.26      |\n",
      "| policy_loss        | -38       |\n",
      "| total_timesteps    | 71369     |\n",
      "| value_loss         | 1.02e+03  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.40013 |\n",
      "| explained_variance | -0.0102   |\n",
      "| fps                | 2362      |\n",
      "| nupdates           | 31        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -37.5     |\n",
      "| total_timesteps    | 73830     |\n",
      "| value_loss         | 1.06e+03  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.17827 |\n",
      "| explained_variance | 0.18      |\n",
      "| fps                | 2356      |\n",
      "| nupdates           | 32        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -36.3     |\n",
      "| total_timesteps    | 76291     |\n",
      "| value_loss         | 975       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 210.21259 |\n",
      "| explained_variance | 0.239     |\n",
      "| fps                | 2351      |\n",
      "| nupdates           | 33        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -37.4     |\n",
      "| total_timesteps    | 78752     |\n",
      "| value_loss         | 1.06e+03  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 210.19176 |\n",
      "| explained_variance | 0.168     |\n",
      "| fps                | 2346      |\n",
      "| nupdates           | 34        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -36.8     |\n",
      "| total_timesteps    | 81213     |\n",
      "| value_loss         | 997       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 212.13673 |\n",
      "| explained_variance | 0.232     |\n",
      "| fps                | 2341      |\n",
      "| nupdates           | 35        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -36.9     |\n",
      "| total_timesteps    | 83674     |\n",
      "| value_loss         | 998       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 212.10555 |\n",
      "| explained_variance | 0.241     |\n",
      "| fps                | 2337      |\n",
      "| nupdates           | 36        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -37       |\n",
      "| total_timesteps    | 86135     |\n",
      "| value_loss         | 959       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 211.66371 |\n",
      "| explained_variance | 0.219     |\n",
      "| fps                | 2333      |\n",
      "| nupdates           | 37        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -37.8     |\n",
      "| total_timesteps    | 88596     |\n",
      "| value_loss         | 1.06e+03  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 210.65309 |\n",
      "| explained_variance | -0.101    |\n",
      "| fps                | 2329      |\n",
      "| nupdates           | 38        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -35.3     |\n",
      "| total_timesteps    | 91057     |\n",
      "| value_loss         | 939       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 210.10608 |\n",
      "| explained_variance | 0.257     |\n",
      "| fps                | 2326      |\n",
      "| nupdates           | 39        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -34.5     |\n",
      "| total_timesteps    | 93518     |\n",
      "| value_loss         | 898       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 209.24161 |\n",
      "| explained_variance | -0.0942   |\n",
      "| fps                | 2322      |\n",
      "| nupdates           | 40        |\n",
      "| policy_entropy     | 1.27      |\n",
      "| policy_loss        | -34.6     |\n",
      "| total_timesteps    | 95979     |\n",
      "| value_loss         | 876       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 209.35309 |\n",
      "| explained_variance | -0.0563   |\n",
      "| fps                | 2319      |\n",
      "| nupdates           | 41        |\n",
      "| policy_entropy     | 1.28      |\n",
      "| policy_loss        | -33.4     |\n",
      "| total_timesteps    | 98440     |\n",
      "| value_loss         | 835       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 209.31024 |\n",
      "| explained_variance | -0.00684  |\n",
      "| fps                | 2316      |\n",
      "| nupdates           | 42        |\n",
      "| policy_entropy     | 1.28      |\n",
      "| policy_loss        | -32.6     |\n",
      "| total_timesteps    | 100901    |\n",
      "| value_loss         | 778       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 209.06866 |\n",
      "| explained_variance | 0.116     |\n",
      "| fps                | 2313      |\n",
      "| nupdates           | 43        |\n",
      "| policy_entropy     | 1.28      |\n",
      "| policy_loss        | -32.3     |\n",
      "| total_timesteps    | 103362    |\n",
      "| value_loss         | 774       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.67924 |\n",
      "| explained_variance | -0.605    |\n",
      "| fps                | 2309      |\n",
      "| nupdates           | 44        |\n",
      "| policy_entropy     | 1.28      |\n",
      "| policy_loss        | -34.1     |\n",
      "| total_timesteps    | 105823    |\n",
      "| value_loss         | 836       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.48198 |\n",
      "| explained_variance | 0.0309    |\n",
      "| fps                | 2307      |\n",
      "| nupdates           | 45        |\n",
      "| policy_entropy     | 1.29      |\n",
      "| policy_loss        | -33.3     |\n",
      "| total_timesteps    | 108284    |\n",
      "| value_loss         | 784       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 206.50284 |\n",
      "| explained_variance | 0.229     |\n",
      "| fps                | 2304      |\n",
      "| nupdates           | 46        |\n",
      "| policy_entropy     | 1.28      |\n",
      "| policy_loss        | -36.8     |\n",
      "| total_timesteps    | 110745    |\n",
      "| value_loss         | 901       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.09496 |\n",
      "| explained_variance | -0.529    |\n",
      "| fps                | 2302      |\n",
      "| nupdates           | 47        |\n",
      "| policy_entropy     | 1.29      |\n",
      "| policy_loss        | -33.4     |\n",
      "| total_timesteps    | 113206    |\n",
      "| value_loss         | 767       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.89679 |\n",
      "| explained_variance | -1        |\n",
      "| fps                | 2299      |\n",
      "| nupdates           | 48        |\n",
      "| policy_entropy     | 1.29      |\n",
      "| policy_loss        | -32.6     |\n",
      "| total_timesteps    | 115667    |\n",
      "| value_loss         | 774       |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.24953 |\n",
      "| explained_variance | -2.01     |\n",
      "| fps                | 2297      |\n",
      "| nupdates           | 49        |\n",
      "| policy_entropy     | 1.29      |\n",
      "| policy_loss        | -31.4     |\n",
      "| total_timesteps    | 118128    |\n",
      "| value_loss         | 698       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 206.59697 |\n",
      "| explained_variance | -1.69     |\n",
      "| fps                | 2294      |\n",
      "| nupdates           | 50        |\n",
      "| policy_entropy     | 1.29      |\n",
      "| policy_loss        | -32.7     |\n",
      "| total_timesteps    | 120589    |\n",
      "| value_loss         | 736       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 206.00647 |\n",
      "| explained_variance | -0.526    |\n",
      "| fps                | 2292      |\n",
      "| nupdates           | 51        |\n",
      "| policy_entropy     | 1.29      |\n",
      "| policy_loss        | -37.3     |\n",
      "| total_timesteps    | 123050    |\n",
      "| value_loss         | 923       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 206.80988 |\n",
      "| explained_variance | -0.21     |\n",
      "| fps                | 2290      |\n",
      "| nupdates           | 52        |\n",
      "| policy_entropy     | 1.29      |\n",
      "| policy_loss        | -35.8     |\n",
      "| total_timesteps    | 125511    |\n",
      "| value_loss         | 875       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 209.00664 |\n",
      "| explained_variance | 0.138     |\n",
      "| fps                | 2288      |\n",
      "| nupdates           | 53        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -37.3     |\n",
      "| total_timesteps    | 127972    |\n",
      "| value_loss         | 936       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.29718 |\n",
      "| explained_variance | -0.0945   |\n",
      "| fps                | 2286      |\n",
      "| nupdates           | 54        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -33.2     |\n",
      "| total_timesteps    | 130433    |\n",
      "| value_loss         | 770       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.92648 |\n",
      "| explained_variance | -0.00375  |\n",
      "| fps                | 2284      |\n",
      "| nupdates           | 55        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -35.9     |\n",
      "| total_timesteps    | 132894    |\n",
      "| value_loss         | 878       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 209.47127 |\n",
      "| explained_variance | -0.355    |\n",
      "| fps                | 2283      |\n",
      "| nupdates           | 56        |\n",
      "| policy_entropy     | 1.29      |\n",
      "| policy_loss        | -32       |\n",
      "| total_timesteps    | 135355    |\n",
      "| value_loss         | 746       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 210.37105 |\n",
      "| explained_variance | -0.216    |\n",
      "| fps                | 2281      |\n",
      "| nupdates           | 57        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -29.6     |\n",
      "| total_timesteps    | 137816    |\n",
      "| value_loss         | 661       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 210.94234 |\n",
      "| explained_variance | -0.0969   |\n",
      "| fps                | 2279      |\n",
      "| nupdates           | 58        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -30.9     |\n",
      "| total_timesteps    | 140277    |\n",
      "| value_loss         | 694       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 211.61942 |\n",
      "| explained_variance | -0.399    |\n",
      "| fps                | 2278      |\n",
      "| nupdates           | 59        |\n",
      "| policy_entropy     | 1.29      |\n",
      "| policy_loss        | -29.3     |\n",
      "| total_timesteps    | 142738    |\n",
      "| value_loss         | 636       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 212.03995 |\n",
      "| explained_variance | -0.0989   |\n",
      "| fps                | 2276      |\n",
      "| nupdates           | 60        |\n",
      "| policy_entropy     | 1.29      |\n",
      "| policy_loss        | -29.2     |\n",
      "| total_timesteps    | 145199    |\n",
      "| value_loss         | 682       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 210.83896 |\n",
      "| explained_variance | 0.2       |\n",
      "| fps                | 2275      |\n",
      "| nupdates           | 61        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -29.7     |\n",
      "| total_timesteps    | 147660    |\n",
      "| value_loss         | 712       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 211.42569 |\n",
      "| explained_variance | -0.016    |\n",
      "| fps                | 2273      |\n",
      "| nupdates           | 62        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -27.6     |\n",
      "| total_timesteps    | 150121    |\n",
      "| value_loss         | 616       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 211.42293 |\n",
      "| explained_variance | 0.14      |\n",
      "| fps                | 2271      |\n",
      "| nupdates           | 63        |\n",
      "| policy_entropy     | 1.29      |\n",
      "| policy_loss        | -29.6     |\n",
      "| total_timesteps    | 152582    |\n",
      "| value_loss         | 678       |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | 211.0847 |\n",
      "| explained_variance | 0.151    |\n",
      "| fps                | 2270     |\n",
      "| nupdates           | 64       |\n",
      "| policy_entropy     | 1.3      |\n",
      "| policy_loss        | -26.2    |\n",
      "| total_timesteps    | 155043   |\n",
      "| value_loss         | 523      |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 209.22829 |\n",
      "| explained_variance | 0.221     |\n",
      "| fps                | 2269      |\n",
      "| nupdates           | 65        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -27.2     |\n",
      "| total_timesteps    | 157504    |\n",
      "| value_loss         | 600       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.96423 |\n",
      "| explained_variance | 0.385     |\n",
      "| fps                | 2268      |\n",
      "| nupdates           | 66        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -24.2     |\n",
      "| total_timesteps    | 159965    |\n",
      "| value_loss         | 448       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 209.16699 |\n",
      "| explained_variance | -0.066    |\n",
      "| fps                | 2267      |\n",
      "| nupdates           | 67        |\n",
      "| policy_entropy     | 1.29      |\n",
      "| policy_loss        | -25.3     |\n",
      "| total_timesteps    | 162426    |\n",
      "| value_loss         | 512       |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | 208.4182 |\n",
      "| explained_variance | 0.159    |\n",
      "| fps                | 2265     |\n",
      "| nupdates           | 68       |\n",
      "| policy_entropy     | 1.29     |\n",
      "| policy_loss        | -26.7    |\n",
      "| total_timesteps    | 164887   |\n",
      "| value_loss         | 541      |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.15205 |\n",
      "| explained_variance | 0.411     |\n",
      "| fps                | 2264      |\n",
      "| nupdates           | 69        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -25.9     |\n",
      "| total_timesteps    | 167348    |\n",
      "| value_loss         | 522       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.57018 |\n",
      "| explained_variance | 0.385     |\n",
      "| fps                | 2263      |\n",
      "| nupdates           | 70        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -25.3     |\n",
      "| total_timesteps    | 169809    |\n",
      "| value_loss         | 477       |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.83504 |\n",
      "| explained_variance | 0.128     |\n",
      "| fps                | 2262      |\n",
      "| nupdates           | 71        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -23       |\n",
      "| total_timesteps    | 172270    |\n",
      "| value_loss         | 387       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.07608 |\n",
      "| explained_variance | 0.371     |\n",
      "| fps                | 2261      |\n",
      "| nupdates           | 72        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -28.6     |\n",
      "| total_timesteps    | 174731    |\n",
      "| value_loss         | 609       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.17767 |\n",
      "| explained_variance | 0.354     |\n",
      "| fps                | 2260      |\n",
      "| nupdates           | 73        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -22.9     |\n",
      "| total_timesteps    | 177192    |\n",
      "| value_loss         | 383       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.95639 |\n",
      "| explained_variance | 0.509     |\n",
      "| fps                | 2259      |\n",
      "| nupdates           | 74        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -24.7     |\n",
      "| total_timesteps    | 179653    |\n",
      "| value_loss         | 437       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.88428 |\n",
      "| explained_variance | 0.251     |\n",
      "| fps                | 2258      |\n",
      "| nupdates           | 75        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -22.3     |\n",
      "| total_timesteps    | 182114    |\n",
      "| value_loss         | 392       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 207.66875 |\n",
      "| explained_variance | 0.45      |\n",
      "| fps                | 2257      |\n",
      "| nupdates           | 76        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -23.2     |\n",
      "| total_timesteps    | 184575    |\n",
      "| value_loss         | 407       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.42075 |\n",
      "| explained_variance | 0.283     |\n",
      "| fps                | 2256      |\n",
      "| nupdates           | 77        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -25.3     |\n",
      "| total_timesteps    | 187036    |\n",
      "| value_loss         | 466       |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 201      |\n",
      "| ep_reward_mean     | 209.1772 |\n",
      "| explained_variance | 0.507    |\n",
      "| fps                | 2255     |\n",
      "| nupdates           | 78       |\n",
      "| policy_entropy     | 1.3      |\n",
      "| policy_loss        | -21.8    |\n",
      "| total_timesteps    | 189497   |\n",
      "| value_loss         | 323      |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.16231 |\n",
      "| explained_variance | 0.0757    |\n",
      "| fps                | 2255      |\n",
      "| nupdates           | 79        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -22.8     |\n",
      "| total_timesteps    | 191958    |\n",
      "| value_loss         | 404       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 208.20555 |\n",
      "| explained_variance | 0.537     |\n",
      "| fps                | 2254      |\n",
      "| nupdates           | 80        |\n",
      "| policy_entropy     | 1.31      |\n",
      "| policy_loss        | -22       |\n",
      "| total_timesteps    | 194419    |\n",
      "| value_loss         | 358       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 201       |\n",
      "| ep_reward_mean     | 209.65532 |\n",
      "| explained_variance | 0.268     |\n",
      "| fps                | 2253      |\n",
      "| nupdates           | 81        |\n",
      "| policy_entropy     | 1.3       |\n",
      "| policy_loss        | -21.1     |\n",
      "| total_timesteps    | 196880    |\n",
      "| value_loss         | 337       |\n",
      "----------------------------------\n",
      "done\n",
      "predict...\n",
      "simulating  results/perus_res__best\n",
      "predicting...\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, 'H'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/base_class.py\u001b[0m in \u001b[0;36m_load_from_file\u001b[0;34m(load_path, load_data, custom_objects)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m                 \u001b[0mnamelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-65fce8de6255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbestname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best/best_perus'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'saved/perusmalli'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcont\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best/best_perus'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 results='results/perus_res_')\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'results/perus_res__best'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Transcend/GitHub/lifecycle-rl/lifecycle_rl/lifecycle.py\u001b[0m in \u001b[0;36mrun_results\u001b[0;34m(self, steps1, steps2, pop, rlmodel, save, debug, simut, results, deterministic, train, predict, batch1, batch2, cont, start_from, bestname, plot)\u001b[0m\n\u001b[1;32m    619\u001b[0m             self.predict_protocol(pop=pop,rlmodel=rlmodel,results=results,\n\u001b[1;32m    620\u001b[0m                           \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                           bestname=results+'_best',onlybest=True)\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisodestats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_simstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_stats'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Transcend/GitHub/lifecycle-rl/lifecycle_rl/lifecycle.py\u001b[0m in \u001b[0;36mpredict_protocol\u001b[0;34m(self, pop, rlmodel, results, load, debug, deterministic, bestname, onlybest)\u001b[0m\n\u001b[1;32m    677\u001b[0m             self.simulate(pop=pop,rlmodel=rlmodel,plot=False,debug=debug,\n\u001b[1;32m    678\u001b[0m                           \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbestname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_100'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m                           deterministic=deterministic)\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     def run_verify(self,n=5,steps1=100,steps2=100,pop=1_000,rlmodel='acktr',\n",
      "\u001b[0;32m/Volumes/Transcend/GitHub/lifecycle-rl/lifecycle_rl/lifecycle.py\u001b[0m in \u001b[0;36msimulate\u001b[0;34m(self, debug, rlmodel, plot, load, pop, max_grad_norm, learning_rate, deterministic, save)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mACER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrlmodel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'acktr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mACKTR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrlmodel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'trpo'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTRPO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/base_class.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, load_path, env, custom_objects, **kwargs)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mextra\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mto\u001b[0m \u001b[0mchange\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mloading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \"\"\"\n\u001b[0;32m--> 839\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'policy_kwargs'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'policy_kwargs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'policy_kwargs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/base_class.py\u001b[0m in \u001b[0;36m_load_from_file\u001b[0;34m(load_path, load_data, custom_objects)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                 \u001b[0mload_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseRLModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_from_file_cloudpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/stable_baselines/common/base_class.py\u001b[0m in \u001b[0;36m_load_from_file_cloudpickle\u001b[0;34m(load_path)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;31m# Here load_path is a file-like object, not a path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'H'."
     ]
    }
   ],
   "source": [
    "cc1=Lifecycle(env='unemployment-v1',minimal=False,mortality=mortality,perustulo=False,\n",
    "              deterministic=deterministic,randomness=randomness)\n",
    "\n",
    "cc1.explain()\n",
    "cc1.run_results(debug=False,steps1=size1,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                train=True,predict=True,batch1=batch1,batch2=batch2,bestname='best/best_perus',\n",
    "                plot=True,save='saved/perusmalli',cont=False,start_from='best/best_perus',\n",
    "                results='results/perus_res_')\n",
    "cc1.render(load='results/perus_res__best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1=Lifecycle(env='unemployment-v1',minimal=False,mortality=mortality,perustulo=False,\n",
    "              deterministic=deterministic,randomness=randomness)\n",
    "\n",
    "cc1.render(load='results/perus_res__best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porrastettu työttömyysturva\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cc2_porras=Lifecycle(env='unemploymentSteps-v1',minimal=False,mortality=mortality,perustulo=False,\n",
    "              randomness=randomness)\n",
    "cc2_porras.run_results(debug=False,steps1=size1,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                train=True,predict=True,batch1=batch1,batch2=batch2,bestname='best/best_steps',plot=True,\n",
    "                save='saved/malli_steps',results='results/steps_res_',start_from='best/best_steps')\n",
    "cc2_porras.render(load='results/steps_res__best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cc2_porras=Lifecycle(env='unemploymentSteps-v1',minimal=False,mortality=mortality,perustulo=False,\n",
    "              randomness=randomness)\n",
    "cc2_porras.render(load='results/steps_res__best')\n",
    "cc2_porras.compare_with(cc1)\n",
    "print(cc1.episodestats.empstate/cc1.n_pop,cc2_porras.episodestats.empstate/cc2_porras.n_pop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cc1.episodestats.empstate[:,1]/cc1.n_pop)\n",
    "plt.plot(cc2_porras.episodestats.empstate[:,1]/cc2_porras.n_pop/10)\n",
    "print(cc1.n_pop,cc2_porras.n_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EK:n malli\n",
    "\n",
    "Lasketaan vertailukelpoiset työllisyysasteet EK:n ehdottamalla mallilla. Mallissa on toteuttu muutoksia ansiosidonnaiseen työttömyysturvaan, asumistukeen, toimeentulotukeen ja verotukseen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc2=Lifecycle(env='unemploymentEK-v1',minimal=False,mortality=mortality,perustulo=False,\n",
    "              randomness=randomness)\n",
    "cc2.run_results(debug=False,steps1=size1,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                train=True,predict=True,batch1=batch1,batch2=batch2,bestname='best/best_ek',plot=True,\n",
    "                save='saved/malli_ek',results='results/ek_res_',start_from='best/best_ek')\n",
    "cc2.render(load='results/ek_res__best')\n",
    "cc2.load_sim(load='results/ek_res__best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc2.compare_with(cc1)\n",
    "#print(cc1.episodestats.empstate/cc1.n_pop,cc2.episodestats.empstate/cc2.n_pop)\n",
    "#cc2.episodestats.load_sim('results/ek_res__best')\n",
    "#cc2.episodestats.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Verifiointi\n",
    "\n",
    "Ajetaan sama simulaatio kaksi kertaa ja tarkastetaan että tulokset ovat sama. Tässä ideana on varmistaa, että satunnaisuus ei sotke tulosten arviointia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Työssäoloehdon pituus 12 kk\n",
    "\n",
    "Entä jos työssäoloehto olisikin 12 kuukautta pitkä nykyisen 6 kuukauden sijaan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc1_toe=Lifecycle(env='unemployment-v1',minimal=False,ansiopvraha_toe=1.0,mortality=mortality,\n",
    "                  perustulo=False,randomness=randomness)\n",
    "cc1_toe.run_results(debug=False,steps1=size1,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                    train=False,predict=True,batch1=batch1,batch2=batch2,bestname='best/best_12kk',plot=True,\n",
    "                    save='saved/malli_12',results='results/12kk_res_',start_from='best/best_12kk')\n",
    "cc1_toe.render(load='results/12kk_res__best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1_toe.compare_with(cc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ansiosidonnaisen päivärahan lyhennys 50 pv\n",
    "\n",
    "Tarkastellaan, miten työllisyyteen vaikuttaisi ansiosidonnaisen päivärahan lyhentäminen 50 päivällä. Tällöin alle kolmen vuoden työhistorialla ansiosidonnaisen päivärahan enimmäiskesto olisi 250 pv ja pidemmällä työhistorialla enimmäiskesto olisi 350 pv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc1_350=Lifecycle(env='unemployment-v1',minimal=False,ansiopvraha_kesto300=250,ansiopvraha_kesto400=350,\n",
    "                  mortality=mortality,perustulo=False,randomness=randomness)\n",
    "cc1_350.run_results(debug=False,steps1=size1,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                    train=False,predict=True,batch1=batch1,batch2=batch2,bestname='best/best_50pv',plot=True,\n",
    "                    save='saved/malli_ek',results='results/50pv_res_')\n",
    "cc1_350.render(load='results/50pv_res__best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1_350.compare_with(cc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Työttömyysputken poisto\n",
    "\n",
    "Työttömyysputki on suosittu elinkaarimalleissa. Tarkastellaan millainen työllisyysvaikutus on putken poistamisella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1_putki=Lifecycle(env='unemployment-v1',minimal=False,include_putki=False,mortality=mortality,\n",
    "                    perustulo=False,randomness=randomness)\n",
    "cc1_putki.run_results(debug=False,steps1=size1,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                      train=True,predict=True,batch1=batch1,batch2=batch2,bestname='best/best_putki',\n",
    "                      plot=True,save='saved/malli_putki',results='results/putki_res_')\n",
    "cc1_350.render(load='results/putki_res__best')\n",
    "cc1_putki.compare_with(cc1)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perustulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cc1_pt=Lifecycle(env='unemployment-v1',minimal=False,perustulo=True,mortality=mortality,\n",
    "                 randomness=randomness)\n",
    "cc1_pt.run_results(debug=False,steps1=size1,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                   train=True,predict=True,batch1=batch1,batch2=batch2,bestname='best/best_pt',plot=True,\n",
    "                   save='saved/malli_pt',results='results/perustulo_res_')\n",
    "cc1_pt.render(load='results/perustulo_res__best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1_pt.compare_with(cc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 300 vs 400 päivän kesto ansiosidonnaisessa\n",
    "\n",
    "Mikä on alle kolmen vuoden työhistorian lyhyemmän (300 pv) ansiosidonnaisen päivärahan enimmäiskeston vaikutus työllisyyteen? Kokeillaan miten työllisyyteen vaikuttaisi sen pidentäminen 400 päivään."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cc1_400=Lifecycle(env='unemployment-v1',minimal=False,ansiopvraha_kesto300=400,mortality=mortality,\n",
    "                  perustulo=False,randomness=randomness)\n",
    "cc1_400.run_results(debug=False,steps1=size1,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                    train=True,predict=True,batch1=batch1,batch2=batch2,bestname='best/best_300pv',plot=True,\n",
    "                    save='saved/malli_300',results='results/300pv_res_')\n",
    "cc1_400.render(load='results/300pv_res__best')\n",
    "cc1_400.compare_with(cc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
