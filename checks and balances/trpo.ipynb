{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison: Reinforced learning vs Dynamic programming\n",
    "\n",
    "Dynamic programming can be used to solve a life cycle model, as shown by Määttänen (2013). Here we compare a rather simple grid based method to solve _unemployment-v0_ environment, and compare the results againt those obtained by Reinforced Learning.\n",
    "\n",
    "Tarkastellussa elinkaarimallissa _unemployment-v0_ on huomioitu vain kolme tilaa: työssä, työtön ja vanhuuseläkkeellä. Jokainen henkilö tekee vuosittain päätöksen työhönosallistumisesta ja alimman vanhuuseläkeiän täyttämisen jälkeen valinnan työn, työttömyyden ja vanhuuseläkkeen välillä. \n",
    "\n",
    "Mallissa palkat ovat stokastisia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifecycle_rl import Lifecycle, DynProgLifecycle\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "# varoitukset piiloon (Stable baseline ei ole vielä Tensorflow 2.0-yhteensopiva, ja Tensorflow 1.5 valittaa paljon)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "size1=10_000_000\n",
    "batch1=32\n",
    "batch2=1_00\n",
    "pop=10_000\n",
    "train_dyn=False\n",
    "sim_dyn=False\n",
    "gamma=0.92\n",
    "debug=False\n",
    "plotdebug=False\n",
    "rlmodel='trpo'\n",
    "\n",
    "file='best/dynamic_prog_V_minimal_gamma092.h5'\n",
    "savedfile='results/dynamic_prog_results_minimal_092'\n",
    "rl_res='results/trpo_res'\n",
    "rl_save='best/trpo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforced Learning\n",
    "\n",
    "Reinforced learning on toinen tapa laskea tuloksia elinkaarimallista. Tässä tarkastelemme kahta eri versiota: Softmax- ja Deterministic. Softmax-mallissa (deterministic=False) käytetään softmax-todennäköisyyksiä seuraavan toimen valinnassa. Deterministisessä valitaan todennäköisin toimi. \n",
    "\n",
    "Deterministinen on näistä kahdesta lähestymistavasta lähempänä taloustieteen utiliteetin maksimointia. Osoittautuukin, että tämä vastaa paremmin hilalaskelmia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stokastinen aktionvalinta softmaxilla\n",
    "\n",
    "Toiminnan tilassa voi valita joko stokastisesti todennäköisyyksien mukaan softmax-funktiolla tai deterministisesti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc6=Lifecycle(env='unemployment-v0',minimal=True,timestep=1.0,gamma=gamma,\n",
    "              plotdebug=plotdebug,exploration=True,exploration_ratio=0.2)\n",
    "cc6.explain()\n",
    "#cc6.run_results(debug=False,steps1=size1,pop=pop,deterministic=False,\n",
    "#                train=False,predict=True,batch1=batch1,save='saved/malli_perusmini99_nondet',\n",
    "#                plot=True,cont=True,start_from='saved/malli_perusmini99_nondet',\n",
    "#                results='results/mini_simut_res_softmax',rlmodel='small_acktr')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc6.run_results(debug=debug,steps1=size1,pop=pop,deterministic=True,\n",
    "                train=True,predict=False,batch1=batch1,save=rl_save,\n",
    "                plot=True,cont=False,start_from=rl_save,plotdebug=plotdebug,log_interval=100,\n",
    "                results=rl_res,rlmodel=rlmodel,learning_rate=0.0003, learning_schedule='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc6.run_results(debug=debug,steps1=50_000,pop=pop,deterministic=True,\n",
    "                train=False,predict=True,batch1=batch2,save=rl_save_sto,\n",
    "                plot=True,cont=True,start_from=rl_save,plotdebug=plotdebug,\n",
    "                results=rl_res,rlmodel=rlmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Tuloksia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc1=Lifecycle(env='unemployment-v0',minimal=True,mortality=False,perustulo=False,\n",
    "              randomness=True,plotdebug=False,timestep=1.0)\n",
    "cc1.render(load=rlsto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#cc3.compare_act(66,cc1,rlmodel='small_acktr',load='saved/malli_perusmini99_nondet',deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cc3b=DynProgLifecycle(env='unemployment-v0',minimal=True,timestep=1.0,gamma=gamma)\n",
    "cc3b.load_sim(savedfile)\n",
    "cc3b.load_V(file)\n",
    "cc3b.compare_ages(cc1,rlmodel=rlmodel,load=rl_save_sto,\n",
    "                 deterministic=True,time_in_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynaaminen ohjelmointi\n",
    "\n",
    "Ajetaan elämänkaarimallia sekä dynaamisella ohjelmoinnilla. Verrataan tuloksia, jotta näemme, miten hyvin RL toimii. Ajoajat eivät ole kovin vertailukelpoisia.\n",
    "\n",
    "Dynaaminen ohjelmointi-koodi toimii ainoastaan minimaalisen mallin kanssa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc3=DynProgLifecycle(env='unemployment-v0',minimal=True,timestep=1.0,gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if train_dyn:\n",
    "    cc3.train(save=file,debug=False)\n",
    "\n",
    "cc3.load_V(file)\n",
    "cc3.explain()\n",
    "if sim_dyn:\n",
    "    cc3.simulate(pop=pop,save=savedfile)\n",
    "else:\n",
    "    cc3.load_sim(savedfile)\n",
    "\n",
    "#cc3.plot_V(2)\n",
    "#cc3.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cc3.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc3.print_q(68,time_in_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc3.print_actV(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc3.print_V(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc3.plot_actV_diff(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc3.plot_Hila(30,emp=0)\n",
    "cc3.plot_Hila(30,emp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc3.plot_Hila(30,emp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc3.plot_Hila(30,diff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age=65\n",
    "cc3b.plot_actHila(age,emp=0,diff=True,time_in_state=1,emp2=1)\n",
    "cc3b.plot_actHila(age,emp=0,diff=True,time_in_state=1,emp2=2)\n",
    "cc3b.plot_actHila(age,emp=1,diff=True,time_in_state=1,emp2=1)\n",
    "cc3b.plot_actHila(age,emp=1,diff=True,time_in_state=1,emp2=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc3b.plot_actHila(67,emp=1,diff=False,time_in_state=1,act=0)\n",
    "cc3b.plot_actHila(67,emp=1,diff=False,time_in_state=1,act=1)\n",
    "cc3b.plot_actHila(67,emp=1,diff=False,time_in_state=1,act=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministinen\n",
    "\n",
    "Deterministinen ennustaminen käyttää samaa sovitetta kuin stok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc7=Lifecycle(env='unemployment-v0',minimal=True,timestep=1.0,gamma=gamma)\n",
    "cc7.explain()\n",
    "cc7.run_results(debug=False,steps1=size1,pop=pop,deterministic=True,\n",
    "                train=False,predict=True,batch1=batch1,save=rl_save_sto,\n",
    "                plot=True,cont=True,start_from=rl_save_sto,\n",
    "                results=rldet,rlmodel=rlmodel,twostage=False)\n",
    "cc7.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Päätöksenteon vertailu\n",
    "\n",
    "Lasketaan vertailukohta RL-menetelmällä ACKTR ja katsotaan paljonko tulokset eroavat.\n",
    "\n",
    "Verrataan ensin hilamallin tuloksia softmax-versioon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cc6=Lifecycle(env='unemployment-v0',minimal=True,timestep=1.0)\n",
    "#cc7=Lifecycle(env='unemployment-v0',minimal=True,timestep=1.0)\n",
    "#cc6.render(load='results/mini_simut_res_softmax')\n",
    "#cc7.render(load='results/mini_simut_res')\n",
    "#cc7.compare_with(cc6)\n",
    "#cc5.compare_with(cc3)\n",
    "cc6.compare_with(cc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sitten verrataan \"determinististä\" sovitetta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc1.compare_with(cc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tehdään sama RL-menetelmällä Deep Q-learning (dqn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deterministinen aktion valinta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cc6=Lifecycle(env='unemployment-v0',minimal=True,timestep=1.0)\n",
    "#cc6.train(steps=1_000_000,cont=False,rlmodel='acktr',save='miniperus')\n",
    "#cc6.simulate(pop=10_000,deterministic=True,load='miniperus',rlmodel='acktr',save='results/acktr_tulokset_miniperus_det')\n",
    "#cc7=Lifecycle(env='unemployment-v0',minimal=True,timestep=1.0)\n",
    "#cc6.train(steps=1_000_000,cont=False,rlmodel='acktr',save='miniperus')\n",
    "#cc7.simulate(pop=2_000,deterministic=True,load='miniperus',rlmodel='dqn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc0=Lifecycle(env='unemployment-v0',minimal=True,timestep=1.0)\n",
    "cc0.load_sim(rlsto)\n",
    "cc1=Lifecycle(env='unemployment-v0',minimal=True,timestep=1.0)\n",
    "cc1.load_sim(rldet)\n",
    "#cc1.render()\n",
    "cc2=Lifecycle(env='unemployment-v0',minimal=True,timestep=1.0)\n",
    "cc2.load_sim(savedfile)\n",
    "#cc2.render()\n",
    "\n",
    "#cc0.compare_with(cc1,label1='softmax',label2='deterministic')\n",
    "cc0.compare_with(cc2,label1='softmax',label2='DP')\n",
    "#cc1.compare_with(cc2,label1='deterministic',label2='DP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc1.compare_with(cc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc2.render()\n",
    "cc1.render()\n",
    "cc0.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Päätöksenteon vertailu\n",
    "\n",
    "Vertaillaan eri mallien tuloksia ja niiden eroja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc6.compare_with(cc3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc7.compare_with(cc3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc6.compare_with(cc7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cc=DynProgLifecycle(env='unemployment-v0',minimal=True,timestep=1.0)\n",
    "ika=55\n",
    "cc.plot_actV(ika,emp=1,time_in_state=0)\n",
    "cc.RL_simulate_V(ika,rlmodel='acktr',emp=1,time_in_state=0,load='miniperus')\n",
    "cc.RL_simulate_V(ika,rlmodel='acktr',emp=0,time_in_state=1,load='miniperus')\n",
    "cc.RL_simulate_V(ika,rlmodel='acktr',emp=2,time_in_state=0,load='miniperus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jakaumat\n",
    "\n",
    "Reinforced Learningiin sisältyy aina epävarmuutta. Sen määrää tuloksissa voi tarkastella esimerkiksi ajamalla saman mallin monta kertaa ja vertaamalla tuloksia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size1=10_000_000\n",
    "size2=0\n",
    "batch1=32\n",
    "batch2=0\n",
    "pop_size=1_000\n",
    "dire='results/v0_qlearn/'\n",
    "deterministic=True\n",
    "n=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2=Lifecycle(env='unemployment-v0',minimal=True,mortality=False,perustulo=False,\n",
    "              randomness=True,plotdebug=False,version=0,timestep=1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2.run_distrib(n=n,startn=0,debug=False,steps1=size1,steps2=size2,pop=pop_size,deterministic=deterministic,\n",
    "                train=True,predict=True,batch1=batch1,batch2=batch2,\n",
    "                save=drl,plot=False,cont=True,start_from=rl_save_sto,results=dire+'distrib_base',\n",
    "                rlmodel=rlmodel,twostage=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2.comp_distribs(load=dire+'distrib_base',n=n,startn=0,stats_results=dire+'distrib_stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2=Lifecycle(env='unemployment-v0',minimal=True,mortality=False,perustulo=False,\n",
    "              randomness=True,plotdebug=False)\n",
    "\n",
    "cc2.render_distrib(stats_results=dire+'distrib_stats',figname='peruskuva_')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
